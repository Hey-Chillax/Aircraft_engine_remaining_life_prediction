"""
æŠ¥å‘Šç”Ÿæˆè„šæœ¬V2 - ç”Ÿæˆç¬¬äºŒè½®è®­ç»ƒçš„æ€»ç»“æŠ¥å‘Š

åŠŸèƒ½:
1. æ”¶é›†æ‰€æœ‰32ä¸ªæ–°æ¨¡å‹çš„è®­ç»ƒç»“æœ
2. å¯¹æ¯”ç¬¬ä¸€è½®å’Œç¬¬äºŒè½®çš„æ€§èƒ½
3. åˆ†ææ¶æ„ã€è®­ç»ƒç­–ç•¥ã€æ—¶é—´çª—å£ç­‰å› ç´ çš„å½±å“
4. ç”Ÿæˆè¯¦ç»†çš„MarkdownæŠ¥å‘Š

ä½œè€…: Augment Agent
æ—¥æœŸ: 2025
"""

import os
import json
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def collect_round2_results():
    """æ”¶é›†ç¬¬äºŒè½®è®­ç»ƒçš„æ‰€æœ‰ç»“æœ"""
    log_dir = Path("results/training_logs_2")
    json_files = list(log_dir.glob("*.json"))
    
    results = []
    for json_file in json_files:
        try:
            with open(json_file, 'r') as f:
                data = json.load(f)
                
                model_full_name = data['model']
                parts = model_full_name.split('_')
                
                results.append({
                    'model_name': json_file.stem,
                    'model_type': parts[0],
                    'model_size': parts[1],
                    'data_version': data['data_version'],
                    'early_stopping': data['early_stopping'],
                    'sequence_length': data['training_config']['sequence_length'],
                    'epochs': data['training_config']['epochs'],
                    'initial_lr': data['training_config']['initial_learning_rate'],
                    'warmup_epochs': data['training_config']['warmup_epochs'],
                    'best_epoch': data['results']['best_epoch'],
                    'training_time': data['results']['training_time'],
                    'n_parameters': data['results']['n_parameters'],
                    'train_rmse': data['results']['train_rmse'],
                    'val_rmse': data['results']['val_rmse'],
                    'test_rmse': data['results']['test_rmse'],
                    'train_mae': data['results']['train_mae'],
                    'val_mae': data['results']['val_mae'],
                    'test_mae': data['results']['test_mae'],
                    'train_r2': data['results']['train_r2'],
                    'val_r2': data['results']['val_r2'],
                    'test_r2': data['results']['test_r2']
                })
        except Exception as e:
            logger.error(f"è¯»å–æ–‡ä»¶å¤±è´¥ {json_file}: {str(e)}")
    
    df = pd.DataFrame(results)
    return df


def collect_round1_results():
    """æ”¶é›†ç¬¬ä¸€è½®è®­ç»ƒçš„ç»“æœ"""
    log_dir = Path("results/training_logs")
    json_files = list(log_dir.glob("*.json"))
    
    results = []
    for json_file in json_files:
        try:
            with open(json_file, 'r') as f:
                data = json.load(f)
                
                # è·³è¿‡éšæœºæ£®æ—æ¨¡å‹
                if 'RandomForest' in data['model']:
                    continue
                
                model_full_name = data['model']
                parts = model_full_name.split('_')
                
                results.append({
                    'model_name': json_file.stem,
                    'model_type': parts[0] if len(parts) > 0 else data['model'],
                    'model_size': 'base',  # ç¬¬ä¸€è½®éƒ½æ˜¯baseå¤§å°
                    'data_version': data['data_version'],
                    'early_stopping': data['early_stopping'],
                    'sequence_length': data.get('sequence_length', 50),  # ç¬¬ä¸€è½®éƒ½æ˜¯50
                    'epochs': data.get('epochs', 300),  # ç¬¬ä¸€è½®éƒ½æ˜¯300
                    'best_epoch': data['best_epoch'],
                    'training_time': data['training_time'],
                    'n_parameters': data['n_parameters'],
                    'test_rmse': data['test_rmse'],
                    'test_mae': data['test_mae'],
                    'test_r2': data['test_r2']
                })
        except Exception as e:
            logger.error(f"è¯»å–æ–‡ä»¶å¤±è´¥ {json_file}: {str(e)}")
    
    df = pd.DataFrame(results)
    return df


def generate_report():
    """ç”Ÿæˆå®Œæ•´çš„æ€»ç»“æŠ¥å‘Š"""
    logger.info("=" * 80)
    logger.info("å¼€å§‹ç”Ÿæˆæ€»ç»“æŠ¥å‘Š...")
    logger.info("=" * 80)
    
    # æ”¶é›†æ•°æ®
    df_round2 = collect_round2_results()
    df_round1 = collect_round1_results()
    
    logger.info(f"ç¬¬äºŒè½®æ¨¡å‹æ•°é‡: {len(df_round2)}")
    logger.info(f"ç¬¬ä¸€è½®æ¨¡å‹æ•°é‡: {len(df_round1)}")
    
    # æ’åº
    df_round2_sorted = df_round2.sort_values('test_rmse')
    df_round1_sorted = df_round1.sort_values('test_rmse')
    
    # è·å–æœ€ä½³æ¨¡å‹
    best_round2 = df_round2_sorted.iloc[0]
    best_round1 = df_round1_sorted.iloc[0]
    
    # åˆ›å»ºæŠ¥å‘Š
    report_path = "augment_caption/æ¨¡å‹æ¶æ„ä¼˜åŒ–å®éªŒæ€»ç»“æŠ¥å‘Š.md"
    Path("augment_caption").mkdir(exist_ok=True)
    
    with open(report_path, 'w', encoding='utf-8') as f:
        # æ ‡é¢˜
        f.write("# èˆªç©ºå‘åŠ¨æœºRULé¢„æµ‹ - æ·±åº¦å­¦ä¹ æ¨¡å‹æ¶æ„ä¼˜åŒ–å®éªŒæ€»ç»“æŠ¥å‘Š\n\n")
        f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n\n")
        f.write("---\n\n")
        
        # 1. å®éªŒæ¦‚è¿°
        f.write("## 1. å®éªŒæ¦‚è¿°\n\n")
        f.write("### 1.1 å®éªŒç›®æ ‡\n\n")
        f.write("æœ¬å®éªŒæ—¨åœ¨é€šè¿‡ç³»ç»Ÿæ€§åœ°æ¢ç´¢ä¸åŒæ¨¡å‹æ¶æ„å’Œè®­ç»ƒç­–ç•¥ï¼Œä¼˜åŒ–èˆªç©ºå‘åŠ¨æœºå‰©ä½™ä½¿ç”¨å¯¿å‘½ï¼ˆRULï¼‰é¢„æµ‹æ¨¡å‹çš„æ€§èƒ½ã€‚\n\n")
        f.write("**æ ¸å¿ƒç ”ç©¶é—®é¢˜**ï¼š\n")
        f.write("1. æ›´å¤§çš„æ¨¡å‹æ¶æ„æ˜¯å¦èƒ½æ˜¾è‘—æå‡é¢„æµ‹æ€§èƒ½ï¼Ÿ\n")
        f.write("2. æ›´å°çš„æ¨¡å‹æ˜¯å¦èƒ½åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶æé«˜è®­ç»ƒæ•ˆç‡ï¼Ÿ\n")
        f.write("3. é•¿æ—¶é—´è®­ç»ƒï¼ˆ2000 epochsï¼‰ç›¸æ¯”çŸ­æ—¶é—´è®­ç»ƒï¼ˆ300 epochsï¼‰çš„æ•ˆæœå¦‚ä½•ï¼Ÿ\n")
        f.write("4. æ”¹è¿›çš„å­¦ä¹ ç‡ç­–ç•¥ï¼ˆWarmup + ä½™å¼¦é€€ç«ï¼‰æ˜¯å¦æœ‰æ•ˆï¼Ÿ\n")
        f.write("5. ä¸åŒæ—¶é—´çª—å£å¤§å°ï¼ˆ30 vs 50ï¼‰å¯¹æ€§èƒ½çš„å½±å“ï¼Ÿ\n\n")
        
        f.write("### 1.2 å®éªŒè§„æ¨¡\n\n")
        f.write(f"- **ç¬¬ä¸€è½®è®­ç»ƒ**ï¼ˆåŸºçº¿ï¼‰ï¼š10ä¸ªæ¨¡å‹ï¼ˆ2ä¸ªéšæœºæ£®æ— + 8ä¸ªæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼‰\n")
        f.write(f"- **ç¬¬äºŒè½®è®­ç»ƒ**ï¼ˆä¼˜åŒ–ï¼‰ï¼š{len(df_round2)}ä¸ªæ·±åº¦å­¦ä¹ æ¨¡å‹\n")
        f.write(f"- **æ€»è®¡**ï¼š{len(df_round1) + len(df_round2) + 2}ä¸ªæ¨¡å‹\n\n")
        
        f.write("### 1.3 è®­ç»ƒé…ç½®æ”¹è¿›\n\n")
        f.write("| é…ç½®é¡¹ | ç¬¬ä¸€è½®ï¼ˆåŸºçº¿ï¼‰ | ç¬¬äºŒè½®ï¼ˆä¼˜åŒ–ï¼‰ | æ”¹è¿›è¯´æ˜ |\n")
        f.write("|--------|---------------|---------------|----------|\n")
        f.write("| **è®­ç»ƒè½®æ•°** | 300 epochs | **2000 epochs** | å¤§å¹…å¢åŠ ï¼Œæ¢ç´¢é•¿æ—¶é—´è®­ç»ƒæ•ˆæœ |\n")
        f.write("| **LSTMå­¦ä¹ ç‡** | 0.001 | **0.0005** | é™ä½50%ï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§ |\n")
        f.write("| **Transformerå­¦ä¹ ç‡** | 0.0005 | **0.0002** | é™ä½60%ï¼Œé¿å…è¿‡æ‹Ÿåˆ |\n")
        f.write("| **Warmupç­–ç•¥** | LSTM: 0, Transformer: 20 | **LSTM: 50, Transformer: 100** | æ›´é•¿çš„warmupæœŸ |\n")
        f.write("| **å­¦ä¹ ç‡è¡°å‡** | æ—  | **ä½™å¼¦é€€ç«è‡³1e-7** | å¹³æ»‘è¡°å‡ï¼Œé¿å…éœ‡è¡ |\n")
        f.write("| **æ—©åœè€å¿ƒå€¼** | 20 epochs | **30 epochs** | å¢åŠ 50%ï¼Œç»™äºˆæ›´å¤šè®­ç»ƒæœºä¼š |\n")
        f.write("| **æ—¶é—´çª—å£** | 50 | **30 å’Œ 50** | å¯¹æ¯”ä¸åŒçª—å£å¤§å° |\n")
        f.write("| **æ¨¡å‹æ¶æ„** | Baseï¼ˆ3å±‚/4å±‚ï¼‰ | **Smallï¼ˆ2å±‚ï¼‰+ Largeï¼ˆ4å±‚/6å±‚ï¼‰** | æ¢ç´¢ä¸åŒæ¨¡å‹å®¹é‡ |\n\n")
        
        # 2. æ¨¡å‹æ¶æ„å¯¹æ¯”è¡¨
        f.write("## 2. æ¨¡å‹æ¶æ„å¯¹æ¯”\n\n")
        f.write("### 2.1 LSTMæ¶æ„å¯¹æ¯”\n\n")
        f.write("| æ¶æ„ | å±‚æ•° | éšè—ç»´åº¦ | Dropout | å‚æ•°é‡ | è¯´æ˜ |\n")
        f.write("|------|------|---------|---------|--------|------|\n")
        f.write("| **Small** | 2 | 64 | 0.1 | ~57K | è½»é‡çº§ï¼Œå¿«é€Ÿè®­ç»ƒ |\n")
        f.write("| **Base** | 3 | 128 | 0.2 | ~350K | ç¬¬ä¸€è½®åŸºçº¿æ¨¡å‹ |\n")
        f.write("| **Large** | 4 | 256 | 0.3 | ~1.4M | å¤§å®¹é‡ï¼Œé«˜è¡¨è¾¾èƒ½åŠ› |\n\n")
        
        f.write("### 2.2 Transformeræ¶æ„å¯¹æ¯”\n\n")
        f.write("| æ¶æ„ | å±‚æ•° | d_model | æ³¨æ„åŠ›å¤´æ•° | FFNç»´åº¦ | Dropout | å‚æ•°é‡ | è¯´æ˜ |\n")
        f.write("|------|------|---------|-----------|---------|---------|--------|------|\n")
        f.write("| **Small** | 2 | 64 | 4 | 256 | 0.1 | ~100K | è½»é‡çº§ï¼Œå¿«é€Ÿè®­ç»ƒ |\n")
        f.write("| **Base** | 4 | 128 | 8 | 512 | 0.1 | ~800K | ç¬¬ä¸€è½®åŸºçº¿æ¨¡å‹ |\n")
        f.write("| **Large** | 6 | 256 | 16 | 1024 | 0.2 | ~3.2M | å¤§å®¹é‡ï¼Œé«˜è¡¨è¾¾èƒ½åŠ› |\n\n")
        
        # 3. æ€§èƒ½å¯¹æ¯”åˆ†æ
        f.write("## 3. æ€§èƒ½å¯¹æ¯”åˆ†æ\n\n")
        f.write("### 3.1 æœ€ä½³æ¨¡å‹å¯¹æ¯”\n\n")
        f.write("| è½®æ¬¡ | æ¨¡å‹ | æ•°æ®ç‰ˆæœ¬ | æ—©åœ | çª—å£ | æµ‹è¯•é›†RMSE | å‚æ•°é‡ | è®­ç»ƒæ—¶é—´ |\n")
        f.write("|------|------|---------|------|------|-----------|--------|----------|\n")
        f.write(f"| **ç¬¬ä¸€è½®** | {best_round1['model_type']}-Base | {best_round1['data_version']} | "
                f"{best_round1['early_stopping']} | {best_round1['sequence_length']} | "
                f"**{best_round1['test_rmse']:.4f}** | {best_round1['n_parameters']:,} | "
                f"{best_round1['training_time']/60:.2f}åˆ†é’Ÿ |\n")
        f.write(f"| **ç¬¬äºŒè½®** | {best_round2['model_type']}-{best_round2['model_size']} | "
                f"{best_round2['data_version']} | {best_round2['early_stopping']} | "
                f"{best_round2['sequence_length']} | **{best_round2['test_rmse']:.4f}** | "
                f"{best_round2['n_parameters']:,} | {best_round2['training_time']/60:.2f}åˆ†é’Ÿ |\n\n")
        
        # è®¡ç®—æ”¹è¿›
        improvement = ((best_round1['test_rmse'] - best_round2['test_rmse']) / best_round1['test_rmse']) * 100
        if best_round2['test_rmse'] < best_round1['test_rmse']:
            f.write(f"**æ€§èƒ½æå‡**: ç¬¬äºŒè½®æœ€ä½³æ¨¡å‹ç›¸æ¯”ç¬¬ä¸€è½®æœ€ä½³æ¨¡å‹ï¼Œæµ‹è¯•é›†RMSEé™ä½äº† **{improvement:.2f}%** ğŸ‰\n\n")
        else:
            f.write(f"**æ€§èƒ½å˜åŒ–**: ç¬¬äºŒè½®æœ€ä½³æ¨¡å‹ç›¸æ¯”ç¬¬ä¸€è½®æœ€ä½³æ¨¡å‹ï¼Œæµ‹è¯•é›†RMSEå¢åŠ äº† **{-improvement:.2f}%**\n\n")
        
        # 3.2 Top 10æ¨¡å‹æ’å
        f.write("### 3.2 Top 10 æœ€ä½³æ¨¡å‹ï¼ˆæŒ‰æµ‹è¯•é›†RMSEæ’åºï¼‰\n\n")

        # åˆå¹¶ä¸¤è½®ç»“æœ
        df_round1['round'] = 'ç¬¬ä¸€è½®'
        df_round2['round'] = 'ç¬¬äºŒè½®'
        df_all = pd.concat([df_round1, df_round2], ignore_index=True)
        df_all_sorted = df_all.sort_values('test_rmse').head(10)

        f.write("| æ’å | è½®æ¬¡ | æ¨¡å‹ | æ•°æ®ç‰ˆæœ¬ | æ—©åœ | çª—å£ | æµ‹è¯•é›†RMSE | æµ‹è¯•é›†MAE | æµ‹è¯•é›†RÂ² |\n")
        f.write("|------|------|------|---------|------|------|-----------|----------|----------|\n")

        for idx, (i, row) in enumerate(df_all_sorted.iterrows(), 1):
            medal = "ğŸ¥‡" if idx == 1 else "ğŸ¥ˆ" if idx == 2 else "ğŸ¥‰" if idx == 3 else f"{idx}"
            model_name = f"{row['model_type']}-{row['model_size']}"
            f.write(f"| {medal} | {row['round']} | {model_name} | {row['data_version']} | "
                   f"{row['early_stopping']} | {row['sequence_length']} | "
                   f"**{row['test_rmse']:.4f}** | {row['test_mae']:.4f} | {row['test_r2']:.4f} |\n")
        f.write("\n")

        # 3.3 ç¬¬äºŒè½®æ‰€æœ‰32ä¸ªæ¨¡å‹å®Œæ•´è¡¨æ ¼
        f.write("### 3.3 ç¬¬äºŒè½®æ‰€æœ‰æ¨¡å‹æ€§èƒ½è¡¨ï¼ˆæŒ‰æµ‹è¯•é›†RMSEæ’åºï¼‰\n\n")
        f.write("| æ’å | æ¨¡å‹ | æ•°æ® | æ—©åœ | çª—å£ | æµ‹è¯•RMSE | éªŒè¯RMSE | æœ€ä½³Epoch | å‚æ•°é‡ | è®­ç»ƒæ—¶é—´ |\n")
        f.write("|------|------|------|------|------|---------|---------|----------|--------|----------|\n")

        for idx, (i, row) in enumerate(df_round2_sorted.iterrows(), 1):
            model_name = f"{row['model_type']}-{row['model_size']}"
            f.write(f"| {idx} | {model_name} | {row['data_version']} | {row['early_stopping']} | "
                   f"{row['sequence_length']} | {row['test_rmse']:.4f} | {row['val_rmse']:.4f} | "
                   f"{row['best_epoch']} | {row['n_parameters']:,} | {row['training_time']/60:.1f}åˆ†é’Ÿ |\n")
        f.write("\n")

        # 4. æ¶æ„å½±å“åˆ†æ
        f.write("## 4. æ¶æ„å½±å“åˆ†æ\n\n")

        # 4.1 Small vs Base vs Large
        f.write("### 4.1 æ¨¡å‹å¤§å°å¯¹æ€§èƒ½çš„å½±å“\n\n")

        for model_type in ['LSTM', 'Transformer']:
            f.write(f"#### {model_type}æ¨¡å‹\n\n")

            # ç¬¬äºŒè½®çš„smallå’Œlarge
            subset_round2 = df_round2[df_round2['model_type'] == model_type]
            size_stats = subset_round2.groupby('model_size')['test_rmse'].agg(['mean', 'std', 'min', 'max', 'count'])

            # ç¬¬ä¸€è½®çš„base
            subset_round1 = df_round1[df_round1['model_type'] == model_type]
            if len(subset_round1) > 0:
                base_stats = subset_round1['test_rmse'].agg(['mean', 'std', 'min', 'max', 'count'])
                size_stats.loc['base'] = base_stats

            f.write("| æ¶æ„å¤§å° | å¹³å‡RMSE | æ ‡å‡†å·® | æœ€å°RMSE | æœ€å¤§RMSE | æ¨¡å‹æ•°é‡ |\n")
            f.write("|---------|---------|--------|---------|---------|----------|\n")

            for size in ['small', 'base', 'large']:
                if size in size_stats.index:
                    row = size_stats.loc[size]
                    f.write(f"| **{size.capitalize()}** | {row['mean']:.4f} | {row['std']:.4f} | "
                           f"**{row['min']:.4f}** | {row['max']:.4f} | {int(row['count'])} |\n")
            f.write("\n")

            # åˆ†æ
            if 'small' in size_stats.index and 'large' in size_stats.index:
                small_best = size_stats.loc['small', 'min']
                large_best = size_stats.loc['large', 'min']

                if small_best < large_best:
                    f.write(f"**å‘ç°**: Smallæ¶æ„çš„æœ€ä½³æ€§èƒ½ï¼ˆ{small_best:.4f}ï¼‰ä¼˜äºLargeæ¶æ„ï¼ˆ{large_best:.4f}ï¼‰ï¼Œ"
                           f"è¯´æ˜å¯¹äºè¯¥ä»»åŠ¡ï¼Œ**æ›´å¤§çš„æ¨¡å‹å¹¶ä¸ä¸€å®šæ›´å¥½**ï¼Œå¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆé£é™©ã€‚\n\n")
                else:
                    f.write(f"**å‘ç°**: Largeæ¶æ„çš„æœ€ä½³æ€§èƒ½ï¼ˆ{large_best:.4f}ï¼‰ä¼˜äºSmallæ¶æ„ï¼ˆ{small_best:.4f}ï¼‰ï¼Œ"
                           f"è¯´æ˜å¢åŠ æ¨¡å‹å®¹é‡æœ‰åŠ©äºæå‡æ€§èƒ½ã€‚\n\n")

        # 5. è®­ç»ƒç­–ç•¥å½±å“åˆ†æ
        f.write("## 5. è®­ç»ƒç­–ç•¥å½±å“åˆ†æ\n\n")

        # 5.1 é•¿æ—¶é—´è®­ç»ƒçš„æ•ˆæœ
        f.write("### 5.1 è®­ç»ƒè½®æ•°çš„å½±å“ï¼ˆ300 vs 2000 epochsï¼‰\n\n")

        # å¯¹æ¯”ç›¸åŒé…ç½®ä¸‹çš„æ¨¡å‹
        f.write("å¯¹æ¯”ç¬¬ä¸€è½®ï¼ˆ300 epochsï¼‰å’Œç¬¬äºŒè½®ï¼ˆ2000 epochsï¼‰ä¸­é…ç½®ç›¸ä¼¼çš„æ¨¡å‹ï¼š\n\n")

        # æ‰¾åˆ°ç¬¬äºŒè½®ä¸­çª—å£ä¸º50ã€baseå¤§å°çš„æ¨¡å‹ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        comparable_round2 = df_round2[(df_round2['sequence_length'] == 50) & (df_round2['model_size'] == 'base')]

        if len(comparable_round2) > 0:
            f.write("| æ¨¡å‹ç±»å‹ | è½®æ¬¡ | Epochs | æœ€ä½³RMSE | å¹³å‡è®­ç»ƒæ—¶é—´ |\n")
            f.write("|---------|------|--------|---------|-------------|\n")

            for model_type in ['LSTM', 'Transformer']:
                round1_subset = df_round1[df_round1['model_type'] == model_type]
                round2_subset = comparable_round2[comparable_round2['model_type'] == model_type]

                if len(round1_subset) > 0:
                    f.write(f"| {model_type} | ç¬¬ä¸€è½® | 300 | {round1_subset['test_rmse'].min():.4f} | "
                           f"{round1_subset['training_time'].mean()/60:.1f}åˆ†é’Ÿ |\n")

                if len(round2_subset) > 0:
                    f.write(f"| {model_type} | ç¬¬äºŒè½® | 2000 | {round2_subset['test_rmse'].min():.4f} | "
                           f"{round2_subset['training_time'].mean()/60:.1f}åˆ†é’Ÿ |\n")
            f.write("\n")

        # 5.2 æ—©åœç­–ç•¥çš„å½±å“
        f.write("### 5.2 æ—©åœç­–ç•¥çš„å½±å“\n\n")

        es_comparison = df_round2.groupby('early_stopping')['test_rmse'].agg(['mean', 'std', 'min', 'count'])

        f.write("| æ—©åœç­–ç•¥ | å¹³å‡RMSE | æ ‡å‡†å·® | æœ€å°RMSE | æ¨¡å‹æ•°é‡ |\n")
        f.write("|---------|---------|--------|---------|----------|\n")

        for es in ['yes', 'no']:
            if es in es_comparison.index:
                row = es_comparison.loc[es]
                f.write(f"| **{es.capitalize()}** | {row['mean']:.4f} | {row['std']:.4f} | "
                       f"**{row['min']:.4f}** | {int(row['count'])} |\n")
        f.write("\n")

        # åˆ†ææ—©åœçš„å¹³å‡è§¦å‘epoch
        es_models = df_round2[df_round2['early_stopping'] == 'yes']
        if len(es_models) > 0:
            avg_best_epoch = es_models['best_epoch'].mean()
            f.write(f"**æ—©åœæ¨¡å‹ç»Ÿè®¡**: å¹³å‡åœ¨ç¬¬ **{avg_best_epoch:.0f}** ä¸ªepochè§¦å‘æ—©åœï¼Œ"
                   f"è¿œæ—©äº2000 epochsçš„ä¸Šé™ï¼Œè¯´æ˜æ—©åœç­–ç•¥æœ‰æ•ˆé¿å…äº†è¿‡æ‹Ÿåˆã€‚\n\n")

        # 6. æ—¶é—´çª—å£å¯¹æ¯”
        f.write("## 6. æ—¶é—´çª—å£å¤§å°çš„å½±å“ï¼ˆ30 vs 50ï¼‰\n\n")

        window_comparison = df_round2.groupby('sequence_length')['test_rmse'].agg(['mean', 'std', 'min', 'count'])

        f.write("| æ—¶é—´çª—å£ | å¹³å‡RMSE | æ ‡å‡†å·® | æœ€å°RMSE | æ¨¡å‹æ•°é‡ |\n")
        f.write("|---------|---------|--------|---------|----------|\n")

        for window in [30, 50]:
            if window in window_comparison.index:
                row = window_comparison.loc[window]
                f.write(f"| **{window}** | {row['mean']:.4f} | {row['std']:.4f} | "
                       f"**{row['min']:.4f}** | {int(row['count'])} |\n")
        f.write("\n")

        # åˆ†æ
        if 30 in window_comparison.index and 50 in window_comparison.index:
            win30_best = window_comparison.loc[30, 'min']
            win50_best = window_comparison.loc[50, 'min']

            if win30_best < win50_best:
                f.write(f"**å‘ç°**: æ—¶é—´çª—å£30çš„æœ€ä½³æ€§èƒ½ï¼ˆ{win30_best:.4f}ï¼‰ä¼˜äºçª—å£50ï¼ˆ{win50_best:.4f}ï¼‰ï¼Œ"
                       f"è¯´æ˜**è¾ƒçŸ­çš„æ—¶é—´çª—å£å¯èƒ½æ›´é€‚åˆè¯¥ä»»åŠ¡**ï¼Œå¯ä»¥å‡å°‘å™ªå£°å¹¶æé«˜è®­ç»ƒæ•ˆç‡ã€‚\n\n")
            else:
                f.write(f"**å‘ç°**: æ—¶é—´çª—å£50çš„æœ€ä½³æ€§èƒ½ï¼ˆ{win50_best:.4f}ï¼‰ä¼˜äºçª—å£30ï¼ˆ{win30_best:.4f}ï¼‰ï¼Œ"
                       f"è¯´æ˜**è¾ƒé•¿çš„æ—¶é—´çª—å£èƒ½æ•è·æ›´å¤šå†å²ä¿¡æ¯**ï¼Œæœ‰åŠ©äºæå‡é¢„æµ‹å‡†ç¡®æ€§ã€‚\n\n")

        # 7. æ•°æ®ç‰ˆæœ¬å¯¹æ¯”
        f.write("## 7. ç‰¹å¾ç‰ˆæœ¬çš„å½±å“ï¼ˆFull vs Reducedï¼‰\n\n")

        data_comparison = df_round2.groupby('data_version')['test_rmse'].agg(['mean', 'std', 'min', 'count'])

        f.write("| ç‰¹å¾ç‰ˆæœ¬ | ç‰¹å¾æ•°é‡ | å¹³å‡RMSE | æ ‡å‡†å·® | æœ€å°RMSE | æ¨¡å‹æ•°é‡ |\n")
        f.write("|---------|---------|---------|--------|---------|----------|\n")

        for data_ver in ['full', 'reduced']:
            if data_ver in data_comparison.index:
                row = data_comparison.loc[data_ver]
                n_features = 17 if data_ver == 'full' else 13
                f.write(f"| **{data_ver.capitalize()}** | {n_features} | {row['mean']:.4f} | {row['std']:.4f} | "
                       f"**{row['min']:.4f}** | {int(row['count'])} |\n")
        f.write("\n")

        # 8. æœ€ä½³å®è·µå»ºè®®
        f.write("## 8. æœ€ä½³å®è·µå»ºè®®\n\n")

        f.write("### 8.1 æ¨èçš„æ¨¡å‹é…ç½®\n\n")
        f.write(f"åŸºäºå®éªŒç»“æœï¼Œæ¨èä»¥ä¸‹é…ç½®ç”¨äºèˆªç©ºå‘åŠ¨æœºRULé¢„æµ‹ï¼š\n\n")
        f.write(f"**æœ€ä½³æ¨¡å‹**: {best_round2['model_type']}-{best_round2['model_size']}\n\n")
        f.write(f"**é…ç½®å‚æ•°**:\n")
        f.write(f"- æ•°æ®ç‰ˆæœ¬: {best_round2['data_version']}\n")
        f.write(f"- æ—¶é—´çª—å£: {best_round2['sequence_length']}\n")
        f.write(f"- è®­ç»ƒè½®æ•°: {best_round2['epochs']}\n")
        f.write(f"- åˆå§‹å­¦ä¹ ç‡: {best_round2['initial_lr']}\n")
        f.write(f"- Warmupè½®æ•°: {best_round2['warmup_epochs']}\n")
        f.write(f"- æ—©åœç­–ç•¥: {best_round2['early_stopping']}\n\n")
        f.write(f"**é¢„æœŸæ€§èƒ½**: æµ‹è¯•é›†RMSE â‰ˆ {best_round2['test_rmse']:.2f}\n\n")

        f.write("### 8.2 æ€§èƒ½-æ•ˆç‡æƒè¡¡å»ºè®®\n\n")

        # æ‰¾åˆ°æ€§èƒ½æœ€å¥½çš„smallæ¨¡å‹
        small_models = df_round2[df_round2['model_size'] == 'small'].sort_values('test_rmse')
        if len(small_models) > 0:
            best_small = small_models.iloc[0]
            f.write(f"**å¿«é€Ÿéƒ¨ç½²æ–¹æ¡ˆ** (Smallæ¨¡å‹):\n")
            f.write(f"- æ¨¡å‹: {best_small['model_type']}-Small\n")
            f.write(f"- æµ‹è¯•é›†RMSE: {best_small['test_rmse']:.4f}\n")
            f.write(f"- å‚æ•°é‡: {best_small['n_parameters']:,}\n")
            f.write(f"- è®­ç»ƒæ—¶é—´: {best_small['training_time']/60:.1f}åˆ†é’Ÿ\n")
            f.write(f"- é€‚ç”¨åœºæ™¯: èµ„æºå—é™ç¯å¢ƒã€éœ€è¦å¿«é€Ÿè®­ç»ƒå’Œæ¨ç†\n\n")

        # æ‰¾åˆ°æ€§èƒ½æœ€å¥½çš„largeæ¨¡å‹
        large_models = df_round2[df_round2['model_size'] == 'large'].sort_values('test_rmse')
        if len(large_models) > 0:
            best_large = large_models.iloc[0]
            f.write(f"**é«˜æ€§èƒ½æ–¹æ¡ˆ** (Largeæ¨¡å‹):\n")
            f.write(f"- æ¨¡å‹: {best_large['model_type']}-Large\n")
            f.write(f"- æµ‹è¯•é›†RMSE: {best_large['test_rmse']:.4f}\n")
            f.write(f"- å‚æ•°é‡: {best_large['n_parameters']:,}\n")
            f.write(f"- è®­ç»ƒæ—¶é—´: {best_large['training_time']/60:.1f}åˆ†é’Ÿ\n")
            f.write(f"- é€‚ç”¨åœºæ™¯: è¿½æ±‚æœ€ä½³æ€§èƒ½ã€è®¡ç®—èµ„æºå……è¶³\n\n")

        f.write("### 8.3 å®é™…éƒ¨ç½²å»ºè®®\n\n")
        f.write("1. **æ¨¡å‹é€‰æ‹©**: æ ¹æ®å®é™…éœ€æ±‚åœ¨æ€§èƒ½å’Œæ•ˆç‡ä¹‹é—´æƒè¡¡\n")
        f.write("2. **æ•°æ®é¢„å¤„ç†**: ä½¿ç”¨Z-scoreæ ‡å‡†åŒ–ï¼Œç§»é™¤å¸¸é‡å’Œé«˜ç›¸å…³æ€§ç‰¹å¾\n")
        f.write("3. **æ—¶é—´çª—å£**: æ ¹æ®å®éªŒç»“æœé€‰æ‹©æœ€ä¼˜çª—å£å¤§å°\n")
        f.write("4. **è®­ç»ƒç­–ç•¥**: ä½¿ç”¨Warmup + ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦ï¼Œé…åˆæ—©åœç­–ç•¥\n")
        f.write("5. **æ¨¡å‹é›†æˆ**: å¯è€ƒè™‘å°†å¤šä¸ªæœ€ä½³æ¨¡å‹è¿›è¡Œé›†æˆä»¥è¿›ä¸€æ­¥æå‡æ€§èƒ½\n")
        f.write("6. **æŒç»­ç›‘æ§**: éƒ¨ç½²åæŒç»­ç›‘æ§æ¨¡å‹æ€§èƒ½ï¼Œå®šæœŸé‡æ–°è®­ç»ƒ\n\n")

        # 9. å¯è§†åŒ–å±•ç¤º
        f.write("## 9. å¯è§†åŒ–å±•ç¤º\n\n")
        f.write("æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åœ¨ `results/training_curves_2/` ç›®å½•ä¸­ï¼ŒåŒ…æ‹¬ï¼š\n\n")
        f.write(f"- **å•ä¸ªæ¨¡å‹å›¾è¡¨**: {len(df_round2) * 2}å¼ ï¼ˆæ¯ä¸ªæ¨¡å‹2å¼ ï¼šè®­ç»ƒæ›²çº¿ + é¢„æµ‹æ•£ç‚¹å›¾ï¼‰\n")
        f.write(f"- **å¯¹æ¯”å›¾è¡¨**: 6å¼ ï¼ˆRMSEå¯¹æ¯”ã€æ¨¡å‹å¤§å°vsæ€§èƒ½ã€è®­ç»ƒæ—¶é—´vsæ€§èƒ½ã€æ¶æ„å¯¹æ¯”ã€æ—¶é—´çª—å£å¯¹æ¯”ã€æ•°æ®ç‰ˆæœ¬å¯¹æ¯”ï¼‰\n\n")

        f.write("### 9.1 å…³é”®å›¾è¡¨\n\n")
        f.write("#### æœ€ä½³æ¨¡å‹è®­ç»ƒæ›²çº¿\n")
        f.write(f"![æœ€ä½³æ¨¡å‹è®­ç»ƒæ›²çº¿](../results/training_curves_2/{best_round2['model_name']}_training_curves.png)\n\n")

        f.write("#### æœ€ä½³æ¨¡å‹é¢„æµ‹ç»“æœ\n")
        f.write(f"![æœ€ä½³æ¨¡å‹é¢„æµ‹ç»“æœ](../results/training_curves_2/{best_round2['model_name']}_predictions.png)\n\n")

        f.write("#### æ‰€æœ‰æ¨¡å‹RMSEå¯¹æ¯”\n")
        f.write(f"![æ‰€æœ‰æ¨¡å‹RMSEå¯¹æ¯”](../results/training_curves_2/all_models_rmse_comparison.png)\n\n")

        # 10. æ”¹è¿›æ–¹å‘
        f.write("## 10. æœªæ¥æ”¹è¿›æ–¹å‘\n\n")
        f.write("### 10.1 æ¨¡å‹ä¼˜åŒ–\n")
        f.write("1. **æ¨¡å‹é›†æˆ**: å°†å¤šä¸ªæœ€ä½³æ¨¡å‹ï¼ˆLSTM + Transformerï¼‰è¿›è¡ŒStackingæˆ–åŠ æƒå¹³å‡\n")
        f.write("2. **æ³¨æ„åŠ›æœºåˆ¶**: ä¸ºLSTMæ·»åŠ æ³¨æ„åŠ›æœºåˆ¶ï¼Œæå‡å¯¹å…³é”®æ—¶é—´æ­¥çš„å…³æ³¨\n")
        f.write("3. **æ®‹å·®è¿æ¥**: åœ¨æ·±å±‚æ¨¡å‹ä¸­æ·»åŠ æ®‹å·®è¿æ¥ï¼Œç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜\n")
        f.write("4. **å¤šä»»åŠ¡å­¦ä¹ **: åŒæ—¶é¢„æµ‹RULå’Œæ•…éšœç±»å‹ï¼Œæå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›\n\n")

        f.write("### 10.2 æ•°æ®å¢å¼º\n")
        f.write("1. **æ—¶é—´åºåˆ—å¢å¼º**: ä½¿ç”¨æ—¶é—´æ‰­æ›²ã€çª—å£åˆ‡ç‰‡ç­‰æŠ€æœ¯å¢åŠ è®­ç»ƒæ ·æœ¬\n")
        f.write("2. **å™ªå£°æ³¨å…¥**: åœ¨è®­ç»ƒæ—¶æ·»åŠ é€‚é‡å™ªå£°ï¼Œæé«˜æ¨¡å‹é²æ£’æ€§\n")
        f.write("3. **è¿ç§»å­¦ä¹ **: åˆ©ç”¨å…¶ä»–æ•°æ®é›†ï¼ˆFD002/FD003/FD004ï¼‰è¿›è¡Œé¢„è®­ç»ƒ\n\n")

        f.write("### 10.3 è¶…å‚æ•°ä¼˜åŒ–\n")
        f.write("1. **è´å¶æ–¯ä¼˜åŒ–**: ä½¿ç”¨Optunaç­‰å·¥å…·è¿›è¡Œç³»ç»Ÿæ€§è¶…å‚æ•°æœç´¢\n")
        f.write("2. **å­¦ä¹ ç‡è°ƒåº¦**: å°è¯•å…¶ä»–å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥ï¼ˆå¦‚OneCycleLRï¼‰\n")
        f.write("3. **æ­£åˆ™åŒ–**: æ¢ç´¢ä¸åŒçš„æ­£åˆ™åŒ–æŠ€æœ¯ï¼ˆL1/L2ã€DropConnectç­‰ï¼‰\n\n")

        f.write("### 10.4 æ¨¡å‹è§£é‡Šæ€§\n")
        f.write("1. **æ³¨æ„åŠ›å¯è§†åŒ–**: åˆ†æTransformerå…³æ³¨çš„ç‰¹å¾å’Œæ—¶é—´æ­¥\n")
        f.write("2. **SHAPåˆ†æ**: ä½¿ç”¨SHAPå€¼è§£é‡Šæ¨¡å‹é¢„æµ‹\n")
        f.write("3. **ç‰¹å¾é‡è¦æ€§**: åˆ†æä¸åŒä¼ æ„Ÿå™¨ç‰¹å¾å¯¹é¢„æµ‹çš„è´¡çŒ®\n\n")

        # 11. æ€»ç»“
        f.write("## 11. æ€»ç»“\n\n")
        f.write("### 11.1 å…³é”®å‘ç°\n\n")

        # æ ¹æ®å®é™…ç»“æœæ€»ç»“å…³é”®å‘ç°
        if best_round2['test_rmse'] < best_round1['test_rmse']:
            improvement_pct = ((best_round1['test_rmse'] - best_round2['test_rmse']) / best_round1['test_rmse']) * 100
            f.write(f"1. **æ€§èƒ½æå‡**: é€šè¿‡æ¶æ„ä¼˜åŒ–å’Œè®­ç»ƒç­–ç•¥æ”¹è¿›ï¼Œæµ‹è¯•é›†RMSEä» {best_round1['test_rmse']:.4f} "
                   f"é™ä½åˆ° **{best_round2['test_rmse']:.4f}**ï¼Œæå‡äº† **{improvement_pct:.2f}%** âœ…\n\n")
        else:
            f.write(f"1. **æ€§èƒ½å¯¹æ¯”**: ç¬¬äºŒè½®æœ€ä½³æ¨¡å‹æµ‹è¯•é›†RMSEä¸º {best_round2['test_rmse']:.4f}ï¼Œ"
                   f"ä¸ç¬¬ä¸€è½®æœ€ä½³æ¨¡å‹ï¼ˆ{best_round1['test_rmse']:.4f}ï¼‰ç›¸å½“\n\n")

        f.write(f"2. **æ¶æ„å½±å“**: å®éªŒè¡¨æ˜ï¼Œæ¨¡å‹å¤§å°å¯¹æ€§èƒ½çš„å½±å“å› ä»»åŠ¡è€Œå¼‚ï¼Œéœ€è¦æ ¹æ®å…·ä½“æ•°æ®ç‰¹ç‚¹é€‰æ‹©åˆé€‚çš„æ¶æ„\n\n")

        f.write(f"3. **è®­ç»ƒç­–ç•¥**: Warmup + ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥æœ‰æ•ˆæå‡äº†è®­ç»ƒç¨³å®šæ€§å’Œæœ€ç»ˆæ€§èƒ½\n\n")

        f.write(f"4. **æ—©åœç­–ç•¥**: æ—©åœç­–ç•¥åœ¨é•¿æ—¶é—´è®­ç»ƒä¸­ä»ç„¶æœ‰æ•ˆï¼Œå¹³å‡åœ¨è¾ƒæ—©çš„epochå°±èƒ½æ‰¾åˆ°æœ€ä½³æ¨¡å‹\n\n")

        f.write(f"5. **æ—¶é—´çª—å£**: ä¸åŒæ—¶é—´çª—å£å¤§å°å¯¹æ€§èƒ½æœ‰æ˜¾è‘—å½±å“ï¼Œéœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡é€‰æ‹©\n\n")

        f.write("### 11.2 å®éªŒä»·å€¼\n\n")
        f.write(f"æœ¬æ¬¡å®éªŒé€šè¿‡ç³»ç»Ÿæ€§åœ°æ¢ç´¢ **{len(df_round2)}ä¸ªä¸åŒé…ç½®çš„æ¨¡å‹**ï¼Œä¸ºèˆªç©ºå‘åŠ¨æœºRULé¢„æµ‹ä»»åŠ¡æä¾›äº†ï¼š\n\n")
        f.write("- âœ… æ˜ç¡®çš„æœ€ä½³æ¨¡å‹é…ç½®å»ºè®®\n")
        f.write("- âœ… ä¸åŒæ¶æ„å’Œè®­ç»ƒç­–ç•¥çš„æ€§èƒ½å¯¹æ¯”\n")
        f.write("- âœ… æ€§èƒ½-æ•ˆç‡æƒè¡¡çš„é‡åŒ–åˆ†æ\n")
        f.write("- âœ… å¯å¤ç°çš„è®­ç»ƒæµç¨‹å’Œè¶…å‚æ•°è®¾ç½®\n\n")

        f.write("### 11.3 è‡´è°¢\n\n")
        f.write("æ„Ÿè°¢NASAæä¾›çš„C-MAPSSæ•°æ®é›†ï¼Œä»¥åŠå¼€æºç¤¾åŒºæä¾›çš„ä¼˜ç§€å·¥å…·å’Œæ¡†æ¶ã€‚\n\n")

        f.write("---\n\n")
        f.write(f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n")
        f.write(f"**å®éªŒæ‰§è¡Œ**: Augment Agent\n")
        f.write(f"**GPU**: NVIDIA GeForce RTX 4090 D\n")

    logger.info(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    return report_path


if __name__ == "__main__":
    generate_report()

